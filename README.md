#  Natural Language Processing (NLP) Labs

This repository contains a series of NLP labs completed during my university coursework. Each lab explores key techniques and models in natural language processing.

##  Lab Overview

###  Lab 1: Text Preprocessing
- Applied detailed preprocessing steps: **tokenization**, **sentence segmentation**, **POS tagging**, **NER**, **lemmatization**, and **stemming**.
- Gained a deep understanding of the preprocessing pipeline in NLP.

###  Lab 2: Text Vectorization
- Explored multiple vectorization techniques: **TF-IDF**, **CBOW**, **Word2Vec**, **Skip-gram**, **FastText**..etc
- Compared and analyzed their behavior and output on different inputs.

###  Lab 3: MLP for Text Classification
- Implemented a **Multilayer Perceptron (MLP)** model.
- Tuned model performance using **hyperparameters** and **Grid Search**.

###  Lab 4: NER with LSTM
- Built a **Named Entity Recognition** model using **Recurrent Neural Networks**.

---

 **Note**: Each lab folder includes a `PDF` file containing the original lab statement.
